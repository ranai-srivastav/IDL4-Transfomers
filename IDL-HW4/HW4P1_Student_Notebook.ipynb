{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3ytyXW-7Q6o"
      },
      "source": [
        "# Setup\n",
        "-  Follow the setup instructions based on your preferred environment!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeJDFDo87Q6s"
      },
      "source": [
        "## Local"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg5oyR8XzQRY"
      },
      "source": [
        "One of our key goals in designing this assignment is to allow you to complete most of the preliminary implementation work locally.  \n",
        "We highly recommend that you **pass all tests locally** using the provided `hw4_data_subset` before moving to a GPU runtime.  \n",
        "To do this, simply:\n",
        "\n",
        "### Create a new conda environment\n",
        "```bash\n",
        "# Be sure to deactivate any active environments first\n",
        "conda create -n hw4 python=3.12.4\n",
        "```\n",
        "\n",
        "### Activate the conda environment\n",
        "```bash\n",
        "conda activate hw4\n",
        "```\n",
        "\n",
        "### Install the dependencies using the provided `requirements.txt`\n",
        "```bash\n",
        "pip install --no-cache-dir --ignore-installed -r requirements.txt\n",
        "```\n",
        "\n",
        "### Ensure that your notebook is in the same working directory as the `Handout`\n",
        "This can be achieved by:\n",
        "1. Physically moving the notebook into the handout directory.\n",
        "2. Changing the notebook’s current working directory to the handout directory using the os.chdir() function.\n",
        "\n",
        "### Open the notebook and select the newly created environment from the kernel selector.\n",
        "\n",
        "If everything was done correctly, You should see atleast the following files in your current working directory after running `!ls`:\n",
        "```\n",
        ".\n",
        "├── README.md\n",
        "├── requirements.txt\n",
        "├── hw4lib/\n",
        "├── mytorch/\n",
        "├── tests/\n",
        "└── hw4_data_subset/\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tub92oPW7Q6t"
      },
      "source": [
        "## Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5qfxCxq7l-f"
      },
      "source": [
        "### Step 1: Get your handout\n",
        "- See writeup for recommended approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "V0wRO-k-7Q6u",
        "outputId": "ffc8882c-ba64-4c20-fcb6-c07534f0e7cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IDL4-Transfomers'...\n",
            "remote: Enumerating objects: 481, done.\u001b[K\n",
            "remote: Counting objects: 100% (481/481), done.\u001b[K\n",
            "remote: Compressing objects: 100% (435/435), done.\u001b[K\n",
            "remote: Total 481 (delta 45), reused 478 (delta 42), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (481/481), 28.78 MiB | 15.74 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Example: My preferred approach\n",
        "import os\n",
        "# Settings -> Developer Settings -> Personal Access Tokens -> Token (classic)\n",
        "os.environ['GITHUB_TOKEN'] = \"your_token_here\"\n",
        "\n",
        "GITHUB_USERNAME = \"ranai-srivastav\"\n",
        "REPO_NAME       = \"IDL4-Transfomers\"\n",
        "TOKEN = userdata.get('GH_PAT')\n",
        "\n",
        "repo_url        = f\"https://{TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
        "!git clone {repo_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmxMiKjIYv2_"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    # To pull latest changes (Must be in the repo dir, use pwd/ls to verify)\n",
        "    !cd {REPO_NAME} && git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfOQStjw7Q6w"
      },
      "source": [
        "### Step 2: Install Dependencies\n",
        "- `NOTE`: Your runtime will be restarted to ensure all dependencies are updated.\n",
        "- `NOTE`: You will see a runtime crashed message, this was intentionally done. Simply move on to the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "maupv9q17Q6w",
        "outputId": "c01c4892-2866-4845-b89d-00c1ef11035a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: annotated-types==0.7.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 1)) (0.7.0)\n",
            "Collecting appnope (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 2))\n",
            "  Downloading appnope-0.1.4-py2.py3-none-any.whl.metadata (908 bytes)\n",
            "Collecting asttokens (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 3))\n",
            "  Downloading asttokens-3.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting beautifulsoup4==4.13.3 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 4))\n",
            "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting certifi==2024.12.14 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 5))\n",
            "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting charset-normalizer==3.4.0 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 6))\n",
            "  Downloading charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Collecting click==8.1.8 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 7))\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting comm (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 8))\n",
            "  Downloading comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting contourpy==1.3.1 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 9))\n",
            "  Downloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: debugpy in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 11)) (1.8.15)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 12)) (4.4.2)\n",
            "Collecting docker-pycreds==0.4.0 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 13))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting exceptiongroup (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 14))\n",
            "  Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting executing (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 15))\n",
            "  Downloading executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting filelock==3.16.1 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 16))\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fonttools==4.55.3 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 17))\n",
            "  Downloading fonttools-4.55.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (165 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec==2024.10.0 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 18))\n",
            "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: gdown==5.2.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 19)) (5.2.0)\n",
            "Requirement already satisfied: gitdb==4.0.12 in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 20)) (4.0.12)\n",
            "Collecting GitPython==3.1.44 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 21))\n",
            "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting huggingface-hub==0.27.0 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 22))\n",
            "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting idna==3.10 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 23))\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 24)) (8.7.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 25)) (6.17.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 26)) (7.34.0)\n",
            "Collecting jedi (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 27))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting Jinja2==3.1.4 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 28))\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: jupyter_client in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 29)) (7.4.9)\n",
            "Requirement already satisfied: jupyter_core in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 30)) (5.9.1)\n",
            "Collecting kaggle==1.7.4.2 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 31))\n",
            "  Downloading kaggle-1.7.4.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting kiwisolver==1.4.7 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 32))\n",
            "  Downloading kiwisolver-1.4.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting lightning-utilities==0.12.0 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 33))\n",
            "  Downloading lightning_utilities-0.12.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting MarkupSafe==3.0.2 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 34))\n",
            "  Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: matplotlib==3.10.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 35)) (3.10.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 36)) (0.2.1)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 37)) (1.3.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 38)) (1.6.0)\n",
            "Collecting networkx==3.4.2 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 39))\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting numpy==2.2.0 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 40))\n",
            "  Downloading numpy-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 41)) (25.0)\n",
            "Collecting pandas==2.2.3 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 42))\n",
            "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: parso in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 43)) (0.8.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 44)) (4.9.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 45)) (0.7.5)\n",
            "Collecting pillow==11.0.0 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 46))\n",
            "  Downloading pillow-11.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 47)) (4.5.0)\n",
            "Requirement already satisfied: prompt_toolkit in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 48)) (3.0.52)\n",
            "Collecting protobuf==5.29.3 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 49))\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 50)) (5.9.5)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 51)) (0.7.0)\n",
            "Collecting pure_eval (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 52))\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pydantic==2.10.5 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 53))\n",
            "  Downloading pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pydantic_core==2.27.2 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 54))\n",
            "  Downloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: Pygments in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 55)) (2.19.2)\n",
            "Collecting pyparsing==3.2.0 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 56))\n",
            "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: PySocks==1.7.1 in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 57)) (1.7.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 58)) (2.9.0.post0)\n",
            "Collecting pytz==2024.2 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 59))\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting PyYAML==6.0.2 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 60))\n",
            "  Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 61)) (26.2.1)\n",
            "Collecting requests==2.32.3 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 62))\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: seaborn==0.13.2 in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 63)) (0.13.2)\n",
            "Collecting sentry-sdk==2.19.2 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 64))\n",
            "  Downloading sentry_sdk-2.19.2-py2.py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting setproctitle==1.3.4 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 65))\n",
            "  Downloading setproctitle-1.3.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting setuptools==75.1.0 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 66))\n",
            "  Downloading setuptools-75.1.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 67)) (1.17.0)\n",
            "Requirement already satisfied: smmap==5.0.2 in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 68)) (5.0.2)\n",
            "Collecting soupsieve==2.6 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 69))\n",
            "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting stack_data (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 70))\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting sympy==1.13.1 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 71))\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tokenizers==0.21.0 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 72))\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting torch==2.5.1 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 73))\n",
            "  Downloading torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchaudio==2.5.1 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 74))\n",
            "  Downloading torchaudio-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting torchinfo==1.8.0 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 75))\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchmetrics==1.6.1 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 76))\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 77)) (6.5.1)\n",
            "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 78)) (4.67.1)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 79)) (5.7.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 80)) (4.15.0)\n",
            "Collecting tzdata==2024.2 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 81))\n",
            "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting urllib3==2.2.3 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 82))\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting wandb==0.19.2 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 83))\n",
            "  Downloading wandb-0.19.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 84)) (0.2.14)\n",
            "Collecting wheel==0.44.0 (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 85))\n",
            "  Downloading wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt (line 86)) (3.23.0)\n",
            "Downloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.0/186.0 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.9/164.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Downloading fonttools-4.55.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.5/450.5 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kaggle-1.7.4.2-py3-none-any.whl (173 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.12.0-py3-none-any.whl (28 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.19.2-py2.py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Downloading setuptools-75.1.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
            "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m132.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl (906.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.5.1-cp312-cp312-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.19.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.44.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appnope-0.1.4-py2.py3-none-any.whl (4.3 kB)\n",
            "Downloading asttokens-3.0.1-py3-none-any.whl (27 kB)\n",
            "Downloading comm-0.2.3-py3-none-any.whl (7.3 kB)\n",
            "Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
            "Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: torchaudio, stack_data, pytz, pure_eval, docker-pycreds, wheel, wandb, urllib3, tzdata, torchmetrics, torchinfo, torch, tokenizers, sympy, soupsieve, setuptools, setproctitle, sentry-sdk, requests, PyYAML, pyparsing, pydantic_core, pydantic, protobuf, pillow, pandas, numpy, networkx, MarkupSafe, lightning-utilities, kiwisolver, kaggle, Jinja2, jedi, idna, huggingface-hub, GitPython, fsspec, fonttools, filelock, executing, exceptiongroup, contourpy, comm, click, charset-normalizer, certifi, beautifulsoup4, asttokens, appnope\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.9.0+cu126\n",
            "    Uninstalling torchaudio-2.9.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.45.1\n",
            "    Uninstalling wheel-0.45.1:\n",
            "      Successfully uninstalled wheel-0.45.1\n",
            "  Attempting uninstall: wandb\n",
            "    Found existing installation: wandb 0.23.0\n",
            "    Uninstalling wandb-0.23.0:\n",
            "      Successfully uninstalled wandb-0.23.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cu126\n",
            "    Uninstalling torch-2.9.0+cu126:\n",
            "      Successfully uninstalled torch-2.9.0+cu126\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: soupsieve\n",
            "    Found existing installation: soupsieve 2.8\n",
            "    Uninstalling soupsieve-2.8:\n",
            "      Successfully uninstalled soupsieve-2.8\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: sentry-sdk\n",
            "    Found existing installation: sentry-sdk 2.46.0\n",
            "    Uninstalling sentry-sdk-2.46.0:\n",
            "      Successfully uninstalled sentry-sdk-2.46.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.3\n",
            "    Uninstalling PyYAML-6.0.3:\n",
            "      Successfully uninstalled PyYAML-6.0.3\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.5\n",
            "    Uninstalling pyparsing-3.2.5:\n",
            "      Successfully uninstalled pyparsing-3.2.5\n",
            "  Attempting uninstall: pydantic_core\n",
            "    Found existing installation: pydantic_core 2.41.4\n",
            "    Uninstalling pydantic_core-2.41.4:\n",
            "      Successfully uninstalled pydantic_core-2.41.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.12.3\n",
            "    Uninstalling pydantic-2.12.3:\n",
            "      Successfully uninstalled pydantic-2.12.3\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.6\n",
            "    Uninstalling networkx-3.6:\n",
            "      Successfully uninstalled networkx-3.6\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.3\n",
            "    Uninstalling MarkupSafe-3.0.3:\n",
            "      Successfully uninstalled MarkupSafe-3.0.3\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.9\n",
            "    Uninstalling kiwisolver-1.4.9:\n",
            "      Successfully uninstalled kiwisolver-1.4.9\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.7.4.5\n",
            "    Uninstalling kaggle-1.7.4.5:\n",
            "      Successfully uninstalled kaggle-1.7.4.5\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.36.0\n",
            "    Uninstalling huggingface-hub-0.36.0:\n",
            "      Successfully uninstalled huggingface-hub-0.36.0\n",
            "  Attempting uninstall: GitPython\n",
            "    Found existing installation: GitPython 3.1.45\n",
            "    Uninstalling GitPython-3.1.45:\n",
            "      Successfully uninstalled GitPython-3.1.45\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: fonttools\n",
            "    Found existing installation: fonttools 4.60.1\n",
            "    Uninstalling fonttools-4.60.1:\n",
            "      Successfully uninstalled fonttools-4.60.1\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.20.0\n",
            "    Uninstalling filelock-3.20.0:\n",
            "      Successfully uninstalled filelock-3.20.0\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.3.3\n",
            "    Uninstalling contourpy-1.3.3:\n",
            "      Successfully uninstalled contourpy-1.3.3\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.1\n",
            "    Uninstalling click-8.3.1:\n",
            "      Successfully uninstalled click-8.3.1\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.4\n",
            "    Uninstalling charset-normalizer-3.4.4:\n",
            "      Successfully uninstalled charset-normalizer-3.4.4\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.11.12\n",
            "    Uninstalling certifi-2025.11.12:\n",
            "      Successfully uninstalled certifi-2025.11.12\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.13.5\n",
            "    Uninstalling beautifulsoup4-4.13.5:\n",
            "      Successfully uninstalled beautifulsoup4-4.13.5\n",
            "Successfully installed GitPython-3.1.44 Jinja2-3.1.4 MarkupSafe-3.0.2 PyYAML-6.0.2 appnope-0.1.4 asttokens-3.0.1 beautifulsoup4-4.13.3 certifi-2024.12.14 charset-normalizer-3.4.0 click-8.1.8 comm-0.2.3 contourpy-1.3.1 docker-pycreds-0.4.0 exceptiongroup-1.3.1 executing-2.2.1 filelock-3.16.1 fonttools-4.55.3 fsspec-2024.10.0 huggingface-hub-0.27.0 idna-3.10 jedi-0.19.2 kaggle-1.7.4.2 kiwisolver-1.4.7 lightning-utilities-0.12.0 networkx-3.4.2 numpy-2.2.0 pandas-2.2.3 pillow-11.0.0 protobuf-5.29.3 pure_eval-0.2.3 pydantic-2.10.5 pydantic_core-2.27.2 pyparsing-3.2.0 pytz-2024.2 requests-2.32.3 sentry-sdk-2.19.2 setproctitle-1.3.4 setuptools-75.1.0 soupsieve-2.6 stack_data-0.6.3 sympy-1.13.1 tokenizers-0.21.0 torch-2.5.1 torchaudio-2.5.1 torchinfo-1.8.0 torchmetrics-1.6.1 tzdata-2024.2 urllib3-2.2.3 wandb-0.19.2 wheel-0.44.0\n"
          ]
        }
      ],
      "source": [
        "%pip install --no-deps -r /content/IDL4-Transfomers/IDL-HW4/requirements.txt\n",
        "import os\n",
        "os.kill(os.getpid(), 9) # NOTE: This will restart the your colab Python runtime (required)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yj32DflNHuI"
      },
      "source": [
        "### Step 3: Obtain Data\n",
        "\n",
        "- `NOTE`: This process will automatically download and unzip data for both `HW4P1` and `HW4P2`.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KeP-XgwYA_M3",
        "outputId": "aabfead6-4d08-404c-c335-190e79bf5349",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 11.9G  100 11.9G    0     0  22.3M      0  0:09:08  0:09:08 --:--:-- 22.9M\n",
            "575M\t/content/hw4_data/hw4p2_data/dev-clean\n",
            "575M\t/content/hw4_data/hw4p2_data\n",
            "28M\t/content/hw4_data/hw4p1_data/val\n",
            "28M\t/content/hw4_data/hw4p1_data/test\n",
            "1.1G\t/content/hw4_data/hw4p1_data/train\n",
            "1.1G\t/content/hw4_data/hw4p1_data\n",
            "1.7G\t/content/hw4_data\n"
          ]
        }
      ],
      "source": [
        "!curl -L -o /content/f25-hw4-data.zip https://www.kaggle.com/api/v1/datasets/download/cmu11785/f25-11785-hw4-data\n",
        "!unzip -q -o /content/f25-hw4-data.zip -d /content/hw4_data\n",
        "!rm -rf /content/f25-hw4-data.zip\n",
        "!du -h --max-depth=2 /content/hw4_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2YwJ0hy7Q6x"
      },
      "source": [
        "### Step 4: Move to Handout Directory\n",
        "You must be within the handout directory for the library imports to work!\n",
        "\n",
        "- `NOTE`: You may have to repeat running this command anytime you restart your runtime.\n",
        "- `NOTE`: You can do a `pwd` to check if you are in the right directory.\n",
        "- `NOTE`: The way it is setup currently, Your data directory should be one level up from your project directory. Keep this in mind when you are setting your `root` in the config file.\n",
        "\n",
        "If everything was done correctly, You should see atleast the following files in your current working directory after running `!ls`:\n",
        "```\n",
        ".\n",
        "├── README.md\n",
        "├── requirements.txt\n",
        "├── hw4lib/\n",
        "├── mytorch/\n",
        "├── tests/\n",
        "└── hw4_data_subset/\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzYdDIxw7Q6x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('IDL-HW4')\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EPDWOj2zQRb"
      },
      "source": [
        "## Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG1hgl5OzQRb"
      },
      "source": [
        "While it is possible to run the notebook on Kaggle, we would recommend against it. This assignment is more resource intensive and may run slower on Kaggle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE98B67SzQRb"
      },
      "source": [
        "### Step 1: Get your handout\n",
        "- See writeup for recommended approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZxCPYQnzQRb"
      },
      "outputs": [],
      "source": [
        "# Example: My preferred approach\n",
        "import os\n",
        "# Settings -> Developer Settings -> Personal Access Tokens -> Token (classic)\n",
        "os.environ['GITHUB_TOKEN'] = \"your_token_here\"\n",
        "\n",
        "GITHUB_USERNAME = \"your_username_here\"\n",
        "REPO_NAME       = \"your_repo_name_here\"\n",
        "TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
        "repo_url        = f\"https://{TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
        "!git clone {repo_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEcrVK2azQRb"
      },
      "outputs": [],
      "source": [
        "# To pull latest changes (Must be in the repo dir, use pwd/ls to verify)\n",
        "!cd {REPO_NAME} && git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOWDhaYfzQRb"
      },
      "source": [
        "### Step 2: Install Dependencies\n",
        "- Simply set the `Environment` setting in the notebook to `Always use latest environment`. No need to install anything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc_kHNdXzQRb"
      },
      "source": [
        "### Step 3: Obtain Data\n",
        "\n",
        "#### ⚠️ Important: Kaggle Users  \n",
        "If you are using Kaggle, **do not manually download the data!** The dataset is large and may exceed your available disk space. Instead, follow these steps to add the dataset directly to your notebook:\n",
        "\n",
        "1. Open your **Kaggle Notebook**.  \n",
        "2. Navigate to **Notebook → Input**.  \n",
        "3. Click **Add Input**.  \n",
        "4. In the search bar, paste the following URL:  \n",
        "   👉 [https://www.kaggle.com/datasets/cmu11785/f25-11785-hw4-data](https://www.kaggle.com/datasets/cmu11785/f25-11785-hw4-data)  \n",
        "5. Click the **➕ (plus sign)** to add the dataset to your notebook.  \n",
        "\n",
        "#### 📌 Note:  \n",
        "This process will automatically download and unzip data for both `HW4P1` and `HW4P2`.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUyrqn8DzQRb"
      },
      "source": [
        "### Step 4: Move to Handout Directory\n",
        "You must be within the handout directory for the library imports to work!\n",
        "\n",
        "- `NOTE`: You may have to repeat running this command anytime you restart your runtime.\n",
        "- `NOTE`: You can do a `pwd` to check if you are in the right directory.\n",
        "- `NOTE`: The way it is setup currently, Your data directory should be one level up from your project directory. Keep this in mind when you are setting your `root` in the config file.\n",
        "\n",
        "If everything was done correctly, You should see atleast the following files in your current working directory after running `!ls`:\n",
        "```\n",
        ".\n",
        "├── README.md\n",
        "├── requirements.txt\n",
        "├── hw4lib/\n",
        "├── mytorch/\n",
        "├── tests/\n",
        "└── hw4_data_subset/\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9M6SncbzQRb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('IDL-HW4')\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP0Aucc7XWXs"
      },
      "source": [
        "## PSC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJm_aSHvXWXs"
      },
      "source": [
        "### 1️⃣ **Step 1 Setting Up Your Environment on Bridges2**\n",
        "\n",
        "❗️⚠️ For this homework, we are **providing shared Datasets and a shared Conda environment** for the entire class.\n",
        "\n",
        "❗️⚠️ So for PSC users, **do not download the data yourself** and **do not need to manually install the packages**!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lf3a_SI7E8l"
      },
      "source": [
        "Follow these steps to set up the environment and start a Jupyter notebook on Bridges2:\n",
        "\n",
        "To run your notebook more efficiently on PSC, we need to use a **Jupyter Server** hosted on a compute node.\n",
        "\n",
        "You can use your prefered way of connecting to the Jupyter Server. Your options should be covered in the docs linked in post 558 @ piazza."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyCQpcT07HQm"
      },
      "source": [
        "**The recommended way of connecting is:**\n",
        "\n",
        "#### **Connect in VSCode**\n",
        "SSH into Bridges2 and navigate to your **Jet directory** (`Jet/home/<your_psc_username>`). Upload your notebook there, and then connect to the Jupyter Server from that directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgivK7YU7J2g"
      },
      "source": [
        "#### **1. SSH into Bridges2**\n",
        "1）Open VS Code and click on the `Extensions` icon in the left sidebar. Make sure the \"**Remote - SSH**\" extension is installed.\n",
        "\n",
        "2）Open the command palette (**Shift+Command+P** on Mac, **Ctrl+Shift+P** on Windows). A search box will appear at the top center. Choose `\"Remote-SSH: Add New SSH Host\"`, then enter:\n",
        "\n",
        "```bash\n",
        "ssh <your_username>@bridges2.psc.edu #change <your_username> to your username\n",
        "```\n",
        "\n",
        "Next, choose `\"/Users/<your_username>/.ssh/config\"` as the config file. A dialog will appear in the bottom right saying \"Host Added\". Click `\"Connect\"`, and then enter your password.\n",
        "\n",
        "(Note: After adding the host once, you can later use `\"Remote-SSH: Connect to Host\"` and select \"bridges2.psc.edu\" from the list.)\n",
        "\n",
        "3）Once connected, click `\"Explorer\"` in the left sidebar > \"Open Folder\", and navigate to your home directory under the project grant:\n",
        "```bash\n",
        "/jet/home/<your_username>  #change <your_username> to your username\n",
        "```\n",
        "\n",
        "4）You can now drag your notebook files directly into the right-hand pane (your remote home directory), or upload them using `scp` into your folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EooKLI57OWj"
      },
      "source": [
        "> ❗️⚠️ The following steps should be executed in the **VSCode integrated terminal**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euHM_evw7Qgz"
      },
      "source": [
        "#### **2. Navigate to Your Directory**\n",
        "Make sure to use this `/jet/home/<your_username>` as your working directory, since all subsequent operations (up to submission) are based on this path.\n",
        "```bash\n",
        "cd /jet/home/<your_username>  #change <your_username> to your username\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cAM9ezJ7S7o"
      },
      "source": [
        "#### **3. Request a Compute Node**\n",
        "```bash\n",
        "interact -p GPU-shared --gres=gpu:v100-32:1 -t 8:00:00 -A cis250019p\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-LgJDnc7UwG"
      },
      "source": [
        "#### **4. Load the Anaconda Module**\n",
        "```bash\n",
        "module load anaconda3\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XhBfy767WjV"
      },
      "source": [
        "#### **5. Activate the provided HW4 Environment**\n",
        "```bash\n",
        "conda deactivate # First, deactivate any existing Conda environment\n",
        "conda activate /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env && export PYTHONNOUSERSITE=1\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwhhtkm97dNC"
      },
      "source": [
        "#### **6. Start Jupyter Notebook**\n",
        "Launch Jupyter Notebook:\n",
        "```bash\n",
        "jupyter notebook --no-browser --ip=0.0.0.0\n",
        "```\n",
        "\n",
        "Go to **Kernel** → **Select Another Kernel** → **Existing Jupyter Server**\n",
        "   Enter the URL of the Jupyter Server:```http://{hostname}:{port}/tree?token={token}```\n",
        "   \n",
        "   *(Usually, this URL appears in the terminal output after you run `jupyter notebook --no-browser --ip=0.0.0.0`, in a line like:  “Jupyter Server is running at: http://...”)*\n",
        "\n",
        "   - eg: `http://v011.ib.bridges2.psc.edu:8888/tree?token=e4b302434e68990f28bc2b4ae8d216eb87eecb7090526249`\n",
        "\n",
        "> **Note**: Replace `{hostname}`, `{port}` and `{token}` with your actual values from the Jupyter output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHvhs7qP7ghQ"
      },
      "source": [
        "After launching the Jupyter notebook, you can run the cells directly inside the notebook — no need to use the terminal for the remaining steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCemuI9_70PG"
      },
      "source": [
        "### 2️⃣ Step 2: Get Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaClGC468DoA"
      },
      "outputs": [],
      "source": [
        "#Make sure you are in your directory\n",
        "!pwd #should be /jet/home/<your_username>, if not, uncomment the following line and replace with your actual username:\n",
        "# %cd /jet/home/<your_username>\n",
        "#TODO: replace the \"<your_username>\" to yours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "simQXvJoXWXs"
      },
      "outputs": [],
      "source": [
        "# Example: My preferred approach\n",
        "import os\n",
        "# Settings -> Developer Settings -> Personal Access Tokens -> Token (classic)\n",
        "os.environ['GITHUB_TOKEN'] = \"your_github_token_here\"\n",
        "\n",
        "GITHUB_USERNAME = \"your_github_username_here\"\n",
        "REPO_NAME       = \"your_github_repo_name_here\"\n",
        "TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
        "repo_url        = f\"https://{TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
        "!git clone {repo_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ibi0yUFXWXs"
      },
      "outputs": [],
      "source": [
        "# To pull latest changes (Must be in the repo dir, use pwd/ls to verify)\n",
        "!cd {REPO_NAME} && git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPU5y0G68brJ"
      },
      "source": [
        "#### **Move to Project Directory**\n",
        "- `NOTE`: You may have to repeat this on anytime you restart your runtime. You can do a `pwd` or `ls` to check if you are in the right directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtwYL_8q8Z5N"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('IDL-HW4')\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVHYLiYb8exP"
      },
      "source": [
        "### 3️⃣ **Step 3: Set up Kaggle API Authentication**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6QWOFH98h07"
      },
      "outputs": [],
      "source": [
        "# TODO: Use the same Kaggle code from HW3P2\n",
        "!mkdir /jet/home/<your_username>/.kaggle #TODO: replace the \"<your_username>\" to yours\n",
        "\n",
        "with open(\"/jet/home/<your_username>/.kaggle/kaggle.json\", \"w+\") as f: #TODO: replace the \"<your_username>\" to yours\n",
        "    f.write('{\"username\":\"<your_username>\",\"key\":\"<your_key>\"}')\n",
        "    # TODO: Put your kaggle username & key here\n",
        "\n",
        "!chmod 600 /jet/home/<your_username>/.kaggle/kaggle.json #TODO: replace the \"<your_username>\" to yours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHsBwCDn8kkq"
      },
      "source": [
        "### 4️⃣ **Step 4: Get Data**\n",
        "\n",
        "❗️⚠️ The data used in this assignment is **already stored in a shared, read-only folder, so you do not need to manually download anything**.\n",
        "\n",
        "Instead, just make sure to replace the dataset path in your notebook code with the correct path from the shared directory.\n",
        "\n",
        "You can run the following block to explore the shared directory structure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFpjyS0z8nO_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "data_path = \"/ocean/projects/cis250019p/mzhang23/TA/HW4/hw4p1_data\" #Shared data path, do not need to change the username to yours\n",
        "print(\"Files in shared hw4p2 dataset:\", os.listdir(data_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc9dAkrP8rof"
      },
      "outputs": [],
      "source": [
        "!apt-get install tree\n",
        "!tree -L 2 /ocean/projects/cis250019p/mzhang23/TA/HW4/hw4p1_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhPm0t5d7Q6z"
      },
      "source": [
        "# Imports\n",
        "\n",
        "- If your setup was done correctly, you should be able to run the following cell without any issues."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "\n",
        "sys.path.append(\"/content/IDL4-Transfomers/IDL-HW4\")\n",
        "os.chdir(\"/content/IDL4-Transfomers/IDL-HW4\")\n",
        "\n",
        "# !pip3 install \"tokenizers>=0.22.0,<=0.23.0\"\n",
        "# !pip3 install \"huggingface-hub>=0.34.0,<1.0\""
      ],
      "metadata": {
        "id": "QVJ9G8OgtqNT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YAJF1-E87Q6z",
        "outputId": "9838563e-9504-4f7c-b02e-bec8d7076178",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from hw4lib.data import (\n",
        "    H4Tokenizer,\n",
        "    LMDataset,\n",
        "    verify_dataloader\n",
        ")\n",
        "from hw4lib.model import (\n",
        "    CausalMask,\n",
        "    PadMask,\n",
        "    PositionalEncoding,\n",
        "    DecoderOnlyTransformer\n",
        ")\n",
        "from hw4lib.utils import (\n",
        "    create_optimizer,\n",
        "    create_scheduler,\n",
        "    plot_lr_schedule\n",
        ")\n",
        "from hw4lib.trainers import (\n",
        "    LMTrainer,\n",
        ")\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import yaml\n",
        "import gc\n",
        "import torch\n",
        "from torchinfo import summary\n",
        "import os\n",
        "import json\n",
        "import tarfile\n",
        "import shutil\n",
        "import wandb\n",
        "import yaml\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PVEPF9nYreol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q4Ccp-M7Q60"
      },
      "source": [
        "# Implementations\n",
        "\n",
        "- `NOTE`: All of these implementations have detailed specification, implementation details, and hints in their respective source files. Make sure to read all of them in their entirety to understand the implementation details!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vqefJri7Q60"
      },
      "source": [
        "## MyTorch Implementations\n",
        "- Modify your `Linear` implementation from HW1P1 to support arbitrary number of dimensions in `mytorch/nn/linear.py`.\n",
        "- Modify your `Softmax` implementation from HW1P1 to support arbitrary number of dimensions in `mytorch/nn/activation.py`.\n",
        "- Implement the `ScaledDotProductAttention` class in `mytorch/nn/scaled_dot_product_attention.py`.\n",
        "- Implement the `MultiHeadAttention` class in `mytorch/nn/multi_head_attention.py`.\n",
        "- Run the cell below to check your implementations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hxzUzzW7Q60"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_mytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8hb5VAN7Q60"
      },
      "source": [
        "## Dataset Implementation\n",
        "- Familiarize yourself with the `tokenize`, `encode`, and `decode` methods of the `H4Tokenizer` class in `hw4lib/data/tokenizer.py`. You will need to make use of these methods in both `HW4P1` and `HW4P2` both in the dataset implementations and during decoding.\n",
        "- Implement the `LMDataset` class in `hw4lib/data/lm_dataset.py`.\n",
        "    - You will have to implement parts of `__init__` and completely implement the `__len__`, `__getitem__` and `collate_fn` methods.\n",
        "- Run the cell below to check your implementation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1oCYvlJ7Q60"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_dataset_lm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6R08H787Q60"
      },
      "source": [
        "## Model Implementations\n",
        "#### Overview:\n",
        "- Implement the `CausalMask` and `PadMask` functions in `hw4lib/modules/masks.py` to handle masking.\n",
        "- Implement the `PositionalEncoding` class in `hw4lib/model/positional_encoding.py` to handle positional encoding.\n",
        "- Implement the Transformer Sublayers: `SelfAttentionLayer` and `FeedForwardLayer` classes in `hw4lib/model/sublayers.py`.\n",
        "- Implement the Transformer Layer: `SelfAttentionDecoderLayer` class in `hw4lib/model/decoder_layers.py`.\n",
        "- Implement the `DecoderOnlyTransformer` class in `hw4lib/model/transformers.py`.\n",
        "- Run the cells below to check your implementation.\n",
        "- `NOTE`: Besides the `DecoderOnlyTransformer` (P1 mandatory, P2 optional), you will use all of the above implementations in both `HW4P1` and `HW4P2`!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6m-85zB7Q61"
      },
      "source": [
        "### Masks\n",
        "- Implement the `PadMask` and `CausalMask` functions in `hw4lib/modules/masks.py`.\n",
        "- Run the cell below to check your implementation.\n",
        "- You will need to make use of these masks in both `HW4P1` and `HW4P2`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di88pr8J7Q61"
      },
      "source": [
        "#### Causal Mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAHwBO7m7Q61"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_mask_causal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCPEtI8X7Q61"
      },
      "source": [
        "#### Padding Mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiZusS-H7Q62"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_mask_padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1ZeV5XM7Q62"
      },
      "source": [
        "#### Optional: Visualize your Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UqY1xD_7Q62"
      },
      "outputs": [],
      "source": [
        "# Dummy data\n",
        "_d_model   = 64\n",
        "_x         = torch.zeros(4, 20, _d_model)\n",
        "_x_len     = torch.tensor([5, 15, 10, 20])\n",
        "_x_causal  = CausalMask(_x)\n",
        "_x_padding = PadMask(_x, _x_len)\n",
        "\n",
        "# Create figure with two subplots side by side\n",
        "fig, mask_axs = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Plot masks\n",
        "masks_and_titles = [\n",
        "    (_x_padding, \"Padding Mask\"),\n",
        "    (_x_causal, \"Causal Mask\")\n",
        "]\n",
        "\n",
        "# Plot each mask\n",
        "images = []\n",
        "for i, (mask, title) in enumerate(masks_and_titles):\n",
        "    im = mask_axs[i].imshow(mask, cmap=\"gray\", aspect='auto')\n",
        "    mask_axs[i].set_title(title, fontsize=8)\n",
        "    images.append(im)\n",
        "\n",
        "# Add colorbar at the bottom\n",
        "fig.subplots_adjust(bottom=0.2)  # Make space for colorbar\n",
        "cbar_ax = fig.add_axes([0.15, 0.1, 0.7, 0.02])  # [left, bottom, width, height]\n",
        "cbar = plt.colorbar(images[0], cax=cbar_ax, orientation='horizontal')\n",
        "cbar.ax.set_xlabel('Mask Values', labelpad=5, fontsize=8)\n",
        "cbar.set_ticks([0, 1])\n",
        "cbar.set_ticklabels(['Attend (0)', 'Ignore/Mask (1)'])\n",
        "cbar.ax.tick_params(labelsize=6)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlkN0B1H7Q63"
      },
      "source": [
        "### Positional Encoding\n",
        "- Implement the `PositionalEncoding` class in `hw4lib/model/positional_encoding.py`.\n",
        "- Run the cell below to check your implementation.\n",
        "- You will need to make use of this positional encoding in both `HW4P1` and `HW4P2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTO-EMdY7Q63"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_positional_encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehZGbq5G7Q64"
      },
      "source": [
        "#### Optional: Visualize your Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cgKYbz47Q64"
      },
      "outputs": [],
      "source": [
        "# Create sample positional encoding\n",
        "d_model = 64\n",
        "max_len = 100\n",
        "pos_encoding = PositionalEncoding(d_model=d_model, max_len=max_len)\n",
        "pe = pos_encoding.pe.squeeze(0).numpy()  # Remove batch dimension and convert to numpy\n",
        "\n",
        "# Create figure with two subplots side by side\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Plot 1: Positional encoding matrix\n",
        "im = ax1.imshow(pe, aspect='auto', cmap='RdBu',\n",
        "                extent=[0, d_model, max_len, 0])  # Flip y-axis to show position top-to-bottom\n",
        "plt.colorbar(im, ax=ax1, label='Encoding Value')\n",
        "ax1.set_xlabel('Dimension')\n",
        "ax1.set_ylabel('Position')\n",
        "ax1.set_title('Positional Encoding Matrix')\n",
        "ax1.grid(False)\n",
        "\n",
        "# Plot 2: Sinusoidal patterns\n",
        "dimensions = [0, 15, 31, 47, 63]  # Plot first few dimensions\n",
        "for dim in dimensions:\n",
        "    ax2.plot(pe[:, dim], label=f'dim {dim}')\n",
        "ax2.set_xlabel('Position')\n",
        "ax2.set_ylabel('Encoding Value')\n",
        "ax2.set_title('Sinusoidal Patterns for Different Dimensions')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSAUWGco7Q64"
      },
      "source": [
        "### Transformer Sublayers\n",
        "- Implement the Transformer Sublayers: `SelfAttentionLayer`, and `FeedForwardLayer` classes in `hw4lib/model/sublayers.py`.\n",
        "- Run the cell below to check your implementation.\n",
        "- You will need to make use of all of these sublayers in both `HW4P1` and `HW4P2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4auGdGYy7Q64"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_sublayer_selfattention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIy1d8757Q64"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_sublayer_feedforward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfGn7MqL7Q65"
      },
      "source": [
        "### Transformer Self-Attention Decoder Layer\n",
        "- Implement the Transformer Layer: `SelfAttentionDecoderLayer` class in `hw4lib/model/decoder_layers.py`.\n",
        "- Run the cell below to check your implementation.\n",
        "- You will need to make use of this sublayer in `HW4P2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8p-8Uff7Q65"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_decoderlayer_selfattention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0NW07hn7Q65"
      },
      "source": [
        "### Decoder-Only Transformer\n",
        "\n",
        "- Implement the `DecoderOnlyTransformer` class in `hw4lib/model/transformers.py`.\n",
        "- Run the cell below to check your implementation.\n",
        "- You will need to make use of in `HW4P1` and optionally `HW4P2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Z1SU9b97Q65"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_transformer_decoder_only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSGdoo9J7Q65"
      },
      "source": [
        "## Decoding Implementation\n",
        "- Implement the `generate_greedy` method of the `SequenceGenerator` class in `hw4lib/decoding/sequence_generator.py`.\n",
        "- Run the cell below to check your implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ks5wXPYS7Q65"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_decoding --mode greedy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiM1ynWhzQRp"
      },
      "source": [
        "## Trainer Implementation\n",
        "You will have to do some minor in-filling for the `LMTrainer` class in `hw4lib/trainers/lm_trainer.py` before you can use it.\n",
        "- Fill in the `TODO`s in the `__init__`.\n",
        "- Fill in the `TODO`s in the `_train_epoch`.\n",
        "- Fill in the `TODO`s in the `_validate_epoch`.\n",
        "- Fill in the `TODO`s in the `generate` method.\n",
        "- Fill in the `TODO`s in the `train` method.\n",
        "\n",
        "`WARNING`: There are no test's for this. Implement carefully!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2-j-cKa7Q65"
      },
      "source": [
        "# Experiments\n",
        "From this point onwards you may want to switch to a `GPU` runtime.\n",
        "- `OBJECTIVE`: You must achieve a per-character perplexity ≤ 3.5 in order to get points for Task 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV2GWmKd7Q65"
      },
      "source": [
        "## Config\n",
        "- You can use the `config.yaml` file to set your config for your ablation study.\n",
        "\n",
        "---\n",
        "### Notes:\n",
        "\n",
        "- Set `tokenization: token_type:` to specify your desired tokenization strategy\n",
        "- You will need to set the root path to your `hw4p1_data` folder in `data: root:`. This will depend on your setup. For eg. if you are following out setup instruction:\n",
        "  - `PSC`: `\"/ocean/projects/cis250019p/mzhang23/TA/HW4/hw4p1_data\"`\n",
        "  - `Colab:`: `\"/content/hw4_data/hw4p1_data\"`\n",
        "  - `Kaggle:`: `\"/kaggle/input/s25-hw4-data/hw4p1_data\"`\n",
        "- There's extra configurations in the `optimizer` section which will only be relevant if you decide to use the `create_optimizer` function we've provided in `hw4lib/utils/create_optimizer.py`.\n",
        "- `BE CAREFUL` while setting numeric values. Eg. `1e-4` will get serialized to a `str` while `1.0e-4` gets serialized to float.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XLChmBx67Q65",
        "outputId": "3dabe9ad-05a5-4870-c311-c1be4650ceb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile config.yaml\n",
        "\n",
        "Name                      : \"Ranai Srivastav\"\n",
        "\n",
        "###### Tokenization ------------------------------------------------------------\n",
        "tokenization:\n",
        "  token_type                : \"char\"       # [char, 1k, 5k, 10k]\n",
        "  token_map :\n",
        "      'char': 'hw4lib/data/tokenizer_jsons/tokenizer_char.json'\n",
        "      '1k'  : 'hw4lib/data/tokenizer_jsons/tokenizer_1000.json'\n",
        "      '5k'  : 'hw4lib/data/tokenizer_jsons/tokenizer_5000.json'\n",
        "      '10k' : 'hw4lib/data/tokenizer_jsons/tokenizer_10000.json'\n",
        "\n",
        "###### Dataset -----------------------------------------------------------------\n",
        "data:                    # Currently setup for Colab assuming out setup\n",
        "  root                 : \"/content/hw4_data/hw4p1_data/\"  # TODO: Set the root path of your data\n",
        "  train_partition      : \"train\"  # train\n",
        "  val_partition        : \"val\"    # val\n",
        "  test_partition       : \"test\"   # test\n",
        "  subset               : 1.0      # Load a subset of the data (for debugging, testing, etc\n",
        "  batch_size           : 256      #\n",
        "  NUM_WORKERS          : 2        # Set to 0 for CPU\n",
        "\n",
        "###### Network Specs -------------------------------------------------------------\n",
        "model: # Decoder-Only Language Model (HW4P1)\n",
        "  d_model                   : 512\n",
        "  d_ff                      : 1024\n",
        "  num_layers                : 4\n",
        "  num_heads                 : 4\n",
        "  dropout                   : 0.25\n",
        "  layer_drop_rate           : 0.05\n",
        "  weight_tying              : False\n",
        "\n",
        "###### Common Training Parameters ------------------------------------------------\n",
        "training:\n",
        "  use_wandb                   : True   # Toggle wandb logging\n",
        "  wandb_run_id                : \"none\" # \"none\" or \"run_id\"\n",
        "  resume                      : False  # Resume an existing run (run_id != 'none')\n",
        "  epochs                      : 100\n",
        "  gradient_accumulation_steps : 1\n",
        "  wandb_project               : \"H4P1-ranais\" # wandb project to log to\n",
        "\n",
        "###### Loss ----------------------------------------------------------------------\n",
        "loss: # Just good ol' CrossEntropy\n",
        "  label_smoothing: 0.05\n",
        "\n",
        "###### Optimizer -----------------------------------------------------------------\n",
        "optimizer:\n",
        "  name: \"adamw\" # Options: sgd, adam, adamw\n",
        "  lr: 5.0e-3   # Base learning rate\n",
        "\n",
        "  # Common parameters\n",
        "  weight_decay: 0.0001\n",
        "\n",
        "  # Parameter groups\n",
        "  param_groups:\n",
        "    - name: self_attn\n",
        "      patterns: []  # Will match all parameters containing keywords set their learning rate to 0.0001\n",
        "      lr: 0.0001    # LR for self_attn\n",
        "      layer_decay:\n",
        "        enabled: False\n",
        "        decay_rate: 0.8\n",
        "\n",
        "    - name: ffn\n",
        "      patterns: [] # Will match all parameters containing \"ffn\" and set their learning rate to 0.0001\n",
        "      lr: 0.0001   # LR for ffn\n",
        "      layer_decay:\n",
        "        enabled: False\n",
        "        decay_rate: 0.8\n",
        "\n",
        "  # Layer-wise learning rates\n",
        "  layer_decay:\n",
        "    enabled: False\n",
        "    decay_rate: 0.75\n",
        "\n",
        "  # SGD specific parameters\n",
        "  sgd:\n",
        "    momentum: 0.9\n",
        "    nesterov: True\n",
        "    dampening: 0\n",
        "\n",
        "  # Adam specific parameters\n",
        "  adam:\n",
        "    betas: [0.9, 0.999]\n",
        "    eps: 1.0e-8\n",
        "    amsgrad: False\n",
        "\n",
        "  # AdamW specific parameters\n",
        "  adamw:\n",
        "    betas: [0.9, 0.999]\n",
        "    eps: 1.0e-8\n",
        "    amsgrad: False\n",
        "\n",
        "###### Scheduler -----------------------------------------------------------------\n",
        "scheduler:\n",
        "  name: \"cosine\"  # Options: reduce_lr, cosine, cosine_warm\n",
        "\n",
        "  # ReduceLROnPlateau specific parameters\n",
        "  reduce_lr:\n",
        "    mode: \"min\"  # Options: min, max\n",
        "    factor: 0.1  # Factor to reduce learning rate by\n",
        "    patience: 10  # Number of epochs with no improvement after which LR will be reduced\n",
        "    threshold: 0.0001  # Threshold for measuring the new optimum\n",
        "    threshold_mode: \"rel\"  # Options: rel, abs\n",
        "    cooldown: 0  # Number of epochs to wait before resuming normal operation\n",
        "    min_lr: 0.0000001  # Minimum learning rate\n",
        "    eps: 1.0e-8  # Minimal decay applied to lr\n",
        "\n",
        "  # CosineAnnealingLR specific parameters\n",
        "  cosine:\n",
        "    T_max: 100  # Maximum number of iterations\n",
        "    eta_min: 1.0e-8  # Minimum learning rate\n",
        "    last_epoch: -1\n",
        "\n",
        "  # CosineAnnealingWarmRestarts specific parameters\n",
        "  cosine_warm:\n",
        "    T_0: 4  # Number of iterations for the first restart\n",
        "    T_mult: 4  # Factor increasing T_i after each restart\n",
        "    eta_min: 0.0000001  # Minimum learning rate\n",
        "    last_epoch: -1\n",
        "\n",
        "  # Warmup parameters (can be used with any scheduler)\n",
        "  warmup:\n",
        "    enabled: True\n",
        "    type: \"exponential\"  # Options: linear, exponential\n",
        "    epochs: 5\n",
        "    start_factor: 0.1\n",
        "    end_factor: 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Fl_9Vv117Q66"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "with open('config.yaml', 'r') as file:\n",
        "    config = yaml.safe_load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu56OILL7Q66"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XBrysj6-7Q66",
        "outputId": "73268854-3c73-4c36-c787-1ec5dacc1307",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "                         Tokenizer Configuration (char)                         \n",
            "--------------------------------------------------------------------------------\n",
            "Vocabulary size:     35\n",
            "\n",
            "Special Tokens:\n",
            "PAD:              0\n",
            "UNK:              1\n",
            "MASK:             2\n",
            "SOS:              3\n",
            "EOS:              4\n",
            "BLANK:            5\n",
            "\n",
            "Validation Example:\n",
            "--------------------------------------------------------------------------------\n",
            "Input text:  [SOS]HI DEEP LEARNERS[EOS]\n",
            "Tokens:      ['[SOS]', 'H', 'I', ' ', 'D', 'E', 'E', 'P', ' ', 'L', 'E', 'A', 'R', 'N', 'E', 'R', 'S', '[EOS]']\n",
            "Token IDs:   [3, 13, 12, 6, 16, 7, 7, 25, 6, 17, 7, 9, 15, 11, 7, 15, 14, 4]\n",
            "Decoded:     [SOS]HI DEEP LEARNERS[EOS]\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "Tokenizer = H4Tokenizer(\n",
        "    token_map  = config['tokenization']['token_map'],\n",
        "    token_type = config['tokenization']['token_type']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-vsGdfu7Q66"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCR3fGoL7Q66",
        "outputId": "b9cd75a8-c3a1-4aa1-a87e-96a4a7fec792",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading transcripts for train partition...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 125864/267178 [01:04<01:03, 2211.70it/s]"
          ]
        }
      ],
      "source": [
        "train_dataset  = LMDataset(\n",
        "    partition  = config['data']['train_partition'],\n",
        "    config     = config['data'],\n",
        "    tokenizer  = Tokenizer\n",
        ")\n",
        "\n",
        "val_dataset    = LMDataset(\n",
        "    partition  = config['data']['val_partition'],\n",
        "    config     = config['data'],\n",
        "    tokenizer  = Tokenizer\n",
        ")\n",
        "\n",
        "test_dataset   = LMDataset(\n",
        "    partition  = config['data']['test_partition'],\n",
        "    config     = config['data'],\n",
        "    tokenizer  = Tokenizer\n",
        ")\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf8Y_COP7Q66"
      },
      "source": [
        "## Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCygmPGopusJ",
        "outputId": "8468f102-41c6-4ca8-bc69-e938887f375c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config['data']['batch_size']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GajQ0LX7Q66"
      },
      "outputs": [],
      "source": [
        "train_loader    = DataLoader(\n",
        "    dataset     = train_dataset,\n",
        "    batch_size  = config['data']['batch_size'],\n",
        "    shuffle     = True,\n",
        "    num_workers = config['data']['NUM_WORKERS'] if device == 'cuda' else 0,\n",
        "    pin_memory  = True,\n",
        "    collate_fn  = train_dataset.collate_fn\n",
        ")\n",
        "\n",
        "val_loader      = DataLoader(\n",
        "    dataset     = val_dataset,\n",
        "    batch_size  = 6,\n",
        "    shuffle     = False,\n",
        "    num_workers = config['data']['NUM_WORKERS'] if device == 'cuda' else 0,\n",
        "    pin_memory  = True,\n",
        "    collate_fn  = val_dataset.collate_fn\n",
        ")\n",
        "\n",
        "test_loader     = DataLoader(\n",
        "    dataset     = test_dataset,\n",
        "    batch_size  = 6,\n",
        "    shuffle     = False,\n",
        "    num_workers = config['data']['NUM_WORKERS'] if device == 'cuda' else 0,\n",
        "    pin_memory  = True,\n",
        "    collate_fn  = test_dataset.collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLKjKWJQ7Q67"
      },
      "source": [
        "### Dataloader Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xY40PhyN7Q67"
      },
      "outputs": [],
      "source": [
        "verify_dataloader(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Shfm0w7E7Q67"
      },
      "outputs": [],
      "source": [
        "verify_dataloader(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlP3xkCg7Q67"
      },
      "outputs": [],
      "source": [
        "verify_dataloader(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCrlXlZH7Q67"
      },
      "source": [
        "## Calculate Max Transcript Length\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIGxOLDU7Q67"
      },
      "source": [
        "Calculating the maximum transcript length across your dataset is a crucial step when working with certain transformer models.\n",
        "-  We'll use sinusoidal positional encodings that must be precomputed up to a fixed maximum length.\n",
        "- This maximum length is a hyperparameter that determines:\n",
        "  - How long of a sequence your model can process\n",
        "  - The size of your positional encoding matrix\n",
        "  - Memory requirements during training and inference\n",
        "- `Requirements`: For this assignment, ensure your positional encodings can accommodate at least the longest sequence in your dataset to prevent truncation. However, you can set this value higher if you anticipate using your language model to work with longer sequences in future tasks (hint: this might be useful for P2! 😉)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWAWHucJ7Q67",
        "outputId": "0a1dd7f8-4b80-47c7-d94e-1bcb2379c514"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Global Max Transcript Length   : 260\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "max_transcript_length = max(train_dataset.text_max_len, val_dataset.text_max_len, test_dataset.text_max_len)\n",
        "print(\"=\"*50)\n",
        "print(f\"{'Global Max Transcript Length':<30} : {max_transcript_length}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot4OuRE27Q67"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qL2-8IbL7Q67",
        "outputId": "b8eb2616-1da7-4e29-a76e-d0c431910e73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of shifted_transcripts :  torch.Size([256, 260])\n",
            "Shape of golden_transcripts  :  torch.Size([256, 260])\n",
            "Shape of transcript_lengths  :  torch.Size([256])\n",
            "===============================================================================================\n",
            "Layer (type:depth-idx)                        Output Shape              Param #\n",
            "===============================================================================================\n",
            "DecoderOnlyTransformer                        [256, 260, 35]            --\n",
            "├─Embedding: 1-1                              [256, 260, 512]           17,920\n",
            "├─PositionalEncoding: 1-2                     [256, 260, 512]           --\n",
            "├─Dropout: 1-3                                [256, 260, 512]           --\n",
            "├─ModuleList: 1-4                             --                        --\n",
            "│    └─SelfAttentionDecoderLayer: 2-1         [256, 260, 512]           --\n",
            "│    │    └─SelfAttentionLayer: 3-1           [256, 260, 512]           1,051,648\n",
            "│    │    └─FeedForwardLayer: 3-2             [256, 260, 512]           1,051,136\n",
            "│    └─SelfAttentionDecoderLayer: 2-2         [256, 260, 512]           --\n",
            "│    │    └─SelfAttentionLayer: 3-3           [256, 260, 512]           1,051,648\n",
            "│    │    └─FeedForwardLayer: 3-4             [256, 260, 512]           1,051,136\n",
            "│    └─SelfAttentionDecoderLayer: 2-3         [256, 260, 512]           --\n",
            "│    │    └─SelfAttentionLayer: 3-5           [256, 260, 512]           1,051,648\n",
            "│    │    └─FeedForwardLayer: 3-6             [256, 260, 512]           1,051,136\n",
            "│    └─SelfAttentionDecoderLayer: 2-4         [256, 260, 512]           --\n",
            "│    │    └─SelfAttentionLayer: 3-7           [256, 260, 512]           1,051,648\n",
            "│    │    └─FeedForwardLayer: 3-8             [256, 260, 512]           1,051,136\n",
            "├─LayerNorm: 1-5                              [256, 260, 512]           1,024\n",
            "├─Linear: 1-6                                 [256, 260, 35]            17,955\n",
            "===============================================================================================\n",
            "Total params: 8,448,035\n",
            "Trainable params: 8,448,035\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 1.09\n",
            "===============================================================================================\n",
            "Input size (MB): 0.53\n",
            "Forward/backward pass size (MB): 6016.49\n",
            "Params size (MB): 16.98\n",
            "Estimated Total Size (MB): 6034.01\n",
            "===============================================================================================\n"
          ]
        }
      ],
      "source": [
        "model_config = config['model']\n",
        "model_config.update({\n",
        "    'max_len': max_transcript_length,\n",
        "    'num_classes': Tokenizer.vocab_size\n",
        "})\n",
        "model = DecoderOnlyTransformer(**model_config)\n",
        "\n",
        "# Get some inputs from the text loader\n",
        "for batch in train_loader:\n",
        "    shifted_transcripts, golden_transcripts, transcript_lengths = batch\n",
        "    print(\"Shape of shifted_transcripts : \", shifted_transcripts.shape)\n",
        "    print(\"Shape of golden_transcripts  : \", golden_transcripts.shape)\n",
        "    print(\"Shape of transcript_lengths  : \", transcript_lengths.shape)\n",
        "    break\n",
        "\n",
        "model_stats = summary(model, input_data=[shifted_transcripts, transcript_lengths])\n",
        "print(model_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH973f3x7Q67"
      },
      "source": [
        "## Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oz7os7UA7Q68"
      },
      "outputs": [],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQAemeOM7Q68"
      },
      "source": [
        "## Trainer\n",
        "\n",
        "Every time you run the trainer, it will create a new directory in the `expts` folder with the following structure:\n",
        "```\n",
        "expts/\n",
        "    └── {run_name}/\n",
        "        ├── config.yaml\n",
        "        ├── model_arch.txt\n",
        "        ├── checkpoints/\n",
        "        │   ├── checkpoint-best-metric-model.pth\n",
        "        │   └── checkpoint-last-epoch-model.pth\n",
        "        ├── attn/\n",
        "        │   └── {attention visualizations}\n",
        "        └── text/\n",
        "            └── {generated text outputs}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcvGSnWi7Q68",
        "outputId": "58ecf792-2e04-49a6-ad7b-ea25a3c5f1d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">test-lm</strong> at: <a href='https://wandb.ai/mrsd-smores/H4P1-ranais/runs/3utyqvsd' target=\"_blank\">https://wandb.ai/mrsd-smores/H4P1-ranais/runs/3utyqvsd</a><br> View project at: <a href='https://wandb.ai/mrsd-smores/H4P1-ranais' target=\"_blank\">https://wandb.ai/mrsd-smores/H4P1-ranais</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251201_062033-3utyqvsd/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ranai/MRSD/idl/hw4/IDL4-Transfomers/IDL-HW4/wandb/run-20251201_062155-avs8cloa</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mrsd-smores/H4P1-ranais/runs/avs8cloa' target=\"_blank\">test-lm</a></strong> to <a href='https://wandb.ai/mrsd-smores/H4P1-ranais' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mrsd-smores/H4P1-ranais' target=\"_blank\">https://wandb.ai/mrsd-smores/H4P1-ranais</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mrsd-smores/H4P1-ranais/runs/avs8cloa' target=\"_blank\">https://wandb.ai/mrsd-smores/H4P1-ranais/runs/avs8cloa</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = LMTrainer(\n",
        "    model=model,\n",
        "    tokenizer=Tokenizer,\n",
        "    config=config,\n",
        "    run_name=\"test-lm\",\n",
        "    config_file=\"config.yaml\",\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJREaFhqiPrT"
      },
      "source": [
        "### Setup Optimizer and Scheduler\n",
        "\n",
        "You can set your own optimizer and scheduler by setting the class members in the `LMTrainer` class.\n",
        "Eg:\n",
        "```python\n",
        "trainer.optimizer = optim.AdamW(model.parameters(), lr=config['optimizer']['lr'], weight_decay=config['optimizer']['weight_decay'])\n",
        "trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max=config['training']['epochs'])\n",
        "```\n",
        "\n",
        "We also provide a utility function to create your own optimizer and scheduler with the congig and some extra bells and whistles. You are free to use it or not. Do read their code and documentation to understand how it works (`hw4lib/utils/*`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WStK_vNzzQRq"
      },
      "source": [
        "#### Setting up the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkljGtIPkATt",
        "outputId": "92b9c241-5ea7-4c98-a31d-6da6817b21d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔧 Configuring Optimizer:\n",
            "├── Type: ADAMW\n",
            "├── Base LR: 0.005\n",
            "├── Weight Decay: 0.0001\n",
            "├── Parameter Groups:\n",
            "│   ├── Group: self_attn\n",
            "│   │   ├── LR: 0.0001\n",
            "│   │   └── Patterns: []\n",
            "│   ├── Group: ffn\n",
            "│   │   ├── LR: 0.0001\n",
            "│   │   └── Patterns: []\n",
            "│   └── Default Group (unmatched parameters)\n",
            "└── AdamW Specific:\n",
            "    ├── Betas: [0.9, 0.999]\n",
            "    ├── Epsilon: 1e-08\n",
            "    └── AMSGrad: False\n"
          ]
        }
      ],
      "source": [
        "trainer.optimizer = create_optimizer(\n",
        "    model=model,\n",
        "    opt_config=config['optimizer']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5Luh4WzzQRq"
      },
      "source": [
        "#### Creating a test scheduler and plotting the learning rate schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inatJGBVi3II",
        "outputId": "e2c4d4ac-f8ff-4658-e2a9-0e73993e8ba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📈 Configuring Learning Rate Scheduler:\n",
            "├── Type: COSINE\n",
            "├── Cosine Annealing Settings:\n",
            "│   ├── T_max: 100 epochs (200 steps)\n",
            "│   └── Min LR: 1e-08\n",
            "├── Warmup Settings:\n",
            "│   ├── Duration: 5 epochs (10 steps)\n",
            "│   ├── Start Factor: 0.1\n",
            "│   └── End Factor: 1.0\n",
            "Warning: Only showing 5 out of 53 parameter groups for clarity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ranai/miniconda3/envs/idl/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:198: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_scheduler = create_scheduler(\n",
        "    optimizer=trainer.optimizer,\n",
        "    scheduler_config=config['scheduler'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")\n",
        "\n",
        "plot_lr_schedule(\n",
        "    scheduler=test_scheduler,\n",
        "    num_epochs=config['training']['epochs'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AxafmUnzQRq"
      },
      "source": [
        "#### Setting up the scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXrwTbqdiPE_",
        "outputId": "6172785b-3476-4dd0-bc58-8fd2a7b76c99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📈 Configuring Learning Rate Scheduler:\n",
            "├── Type: COSINE\n",
            "├── Cosine Annealing Settings:\n",
            "│   ├── T_max: 100 epochs (200 steps)\n",
            "│   └── Min LR: 1e-08\n",
            "├── Warmup Settings:\n",
            "│   ├── Duration: 5 epochs (10 steps)\n",
            "│   ├── Start Factor: 0.1\n",
            "│   └── End Factor: 1.0\n"
          ]
        }
      ],
      "source": [
        "trainer.scheduler = create_scheduler(\n",
        "    optimizer=trainer.optimizer,\n",
        "    scheduler_config=config['scheduler'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XI0dHJB7Q68"
      },
      "source": [
        "# Train\n",
        "- Set your epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nugAKoOw7Q68",
        "outputId": "13e27ab1-610c-40f7-bdd5-c9ae6e7041a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 134.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 27.88 MiB is free. Including non-PyTorch memory, this process has 3.66 GiB memory in use. Of the allocated memory 3.34 GiB is allocated by PyTorch, and 236.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/MRSD/idl/hw4/IDL4-Transfomers/IDL-HW4/hw4lib/trainers/lm_trainer.py:252\u001b[0m, in \u001b[0;36mLMTrainer.train\u001b[0;34m(self, train_dataloader, val_dataloader, epochs)\u001b[0m\n\u001b[1;32m    247\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_epoch \u001b[38;5;241m+\u001b[39m epochs):\n\u001b[1;32m    250\u001b[0m     \n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# TODO: Train for one epoch\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m     train_metrics, train_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# TODO: Validate\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     val_metrics, val_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_epoch(val_dataloader)\n",
            "File \u001b[0;32m~/MRSD/idl/hw4/IDL4-Transfomers/IDL-HW4/hw4lib/trainers/lm_trainer.py:92\u001b[0m, in \u001b[0;36mLMTrainer._train_epoch\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     87\u001b[0m lengths \u001b[38;5;241m=\u001b[39m lengths\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16):\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# TODO: Get raw logits and attention weights from model\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     raw_preds, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets_shifted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# TODO: Calculate raw loss first\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# What is the shape of raw_preds and targets_golden? \u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# Would you need to change the shape of the inputs to the criterion?\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# Hint: See the documentation for CrossEntropyLoss\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# Input needs to be (Batch, class IDs, *) -> in comes (B, T)\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28mprint\u001b[39m(raw_preds\u001b[38;5;241m.\u001b[39mshape, targets_golden\u001b[38;5;241m.\u001b[39mshape)\n",
            "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/MRSD/idl/hw4/IDL4-Transfomers/IDL-HW4/hw4lib/model/transformers.py:171\u001b[0m, in \u001b[0;36mDecoderOnlyTransformer.forward\u001b[0;34m(self, padded_targets, target_lengths)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# TODO: Pass through decoder layer\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m dec_embs_pe, attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdec_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_embs_pe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_mask_dec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# TODO: Save attention weights  \u001b[39;00m\n\u001b[1;32m    174\u001b[0m runnint_att[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_dec_self\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m attention\n",
            "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/MRSD/idl/hw4/IDL4-Transfomers/IDL-HW4/hw4lib/model/decoder_layers.py:74\u001b[0m, in \u001b[0;36mSelfAttentionDecoderLayer.forward\u001b[0;34m(self, x, key_padding_mask, attn_mask)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, key_padding_mask: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, attn_mask: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    Forward pass for the DecoderLayer1.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m        mha_attn_weights (torch.Tensor): The attention weights. shape: (batch_size, seq_len, seq_len)   \u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     mha_attn_out, mha_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     ffn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(mha_attn_out)\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# Return both the layer output and the attention weights as promised by the signature\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/MRSD/idl/hw4/IDL4-Transfomers/IDL-HW4/hw4lib/model/sublayers.py:70\u001b[0m, in \u001b[0;36mSelfAttentionLayer.forward\u001b[0;34m(self, x, key_padding_mask, attn_mask)\u001b[0m\n\u001b[1;32m     67\u001b[0m post_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Use post-norm for query, key, and value to keep shapes consistent and batched\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m mha_attn_out, mha_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmha\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m layer_out \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(mha_attn_out)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m layer_out, mha_attn_weights\n",
            "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.10/site-packages/torch/nn/modules/activation.py:1373\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1347\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1348\u001b[0m         query,\n\u001b[1;32m   1349\u001b[0m         key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m   1371\u001b[0m     )\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1373\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
            "File \u001b[0;32m~/miniconda3/envs/idl/lib/python3.10/site-packages/torch/nn/functional.py:6378\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropout_p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m   6376\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m dropout(attn_output_weights, p\u001b[38;5;241m=\u001b[39mdropout_p)\n\u001b[0;32m-> 6378\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6380\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   6381\u001b[0m     attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(tgt_len \u001b[38;5;241m*\u001b[39m bsz, embed_dim)\n\u001b[1;32m   6382\u001b[0m )\n\u001b[1;32m   6383\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 134.00 MiB. GPU 0 has a total capacity of 3.71 GiB of which 27.88 MiB is free. Including non-PyTorch memory, this process has 3.66 GiB memory in use. Of the allocated memory 3.34 GiB is allocated by PyTorch, and 236.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "trainer.train(train_loader, val_loader, epochs=config['training']['epochs'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j55r9gK_7Q68"
      },
      "source": [
        "# Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72D0yzHr7Q68"
      },
      "outputs": [],
      "source": [
        "test_metrics, test_generation_results = trainer.evaluate(test_loader)\n",
        "# Cleanup\n",
        "trainer.cleanup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHw8LJp07Q68"
      },
      "source": [
        "# Submission\n",
        "To submit your assignment, you will need to create a `handin.tar` with the following directory structure:\n",
        "\n",
        "```\n",
        "handin/\n",
        "├── mytorch/                     # Your implemented modules\n",
        "├── test_metrics.json            # Results from evaluation\n",
        "├── test_generated_results.json  # Sample text generations\n",
        "└── model_arch.txt               # Model architecture summary\n",
        "```\n",
        "\n",
        "- Simply run the cell below once you are satisfied with your current state and this will create the `handin.tar` file.\n",
        "- After running the above cell, you should see the handin.tar file in the current directory\n",
        "- Upload the `handin.tar` file to the `HW4P1` assignment on Autolab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVSPaoOF7Q68"
      },
      "outputs": [],
      "source": [
        "# Create temporary handin directory\n",
        "if os.path.exists('handin'):\n",
        "    shutil.rmtree('handin')\n",
        "os.makedirs('handin')\n",
        "\n",
        "# Copy mytorch directory\n",
        "shutil.copytree('mytorch', 'handin/mytorch')\n",
        "\n",
        "# Save final results\n",
        "with open('handin/test_metrics.json', 'w') as f:\n",
        "    json.dump(test_metrics, f, indent=4)\n",
        "\n",
        "with open('handin/test_generated_results.json', 'w') as f:\n",
        "    json.dump(test_generation_results['greedy'], f, indent=4)\n",
        "\n",
        "# Save model architecture\n",
        "with open('handin/model_arch.txt', 'w') as f:\n",
        "    f.write(str(model_stats))\n",
        "\n",
        "# Create tar file with all exclusions handled by filter\n",
        "with tarfile.open('handin.tar', 'w') as tar:\n",
        "    def filter_files(tarinfo):\n",
        "        # Skip unwanted files\n",
        "        if any(pattern in tarinfo.name for pattern in [\n",
        "            '.DS_Store',\n",
        "            '__pycache__',\n",
        "            '.pyc'\n",
        "        ]):\n",
        "            return None\n",
        "        return tarinfo\n",
        "\n",
        "    tar.add('handin', arcname='handin', filter=filter_files)\n",
        "\n",
        "# Cleanup\n",
        "shutil.rmtree('handin')\n",
        "\n",
        "print(\"Created handin.tar successfully!\")\n",
        "\n",
        "## After running the above cell, you should see the handin.tar file in the current directory\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rpl0bTJpusN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qQG51p6e7Q6x"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "idl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}